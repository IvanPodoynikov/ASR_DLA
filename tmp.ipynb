{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0563ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5ac52e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.text_encoder import CTCTextEncoder\n",
    "text_encoder = CTCTextEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4f54811",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'wwwwwaaa losseer'\n",
    "encoded = text_encoder.encode(text)\n",
    "assert 'wa loser' == text_encoder.ctc_decode(encoded.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0bc7a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "encoded = text_encoder.encode(text)\n",
    "assert '' == text_encoder.ctc_decode(encoded.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8db66824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: editdistance in ./project_env/lib/python3.11/site-packages (0.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "037fc30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind2char = text_encoder.ind2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c0502f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_decode1(inds) -> str:\n",
    "    \"\"\"\n",
    "    Decoding with CTC.\n",
    "    \"\"\"\n",
    "    text = ''\n",
    "    prev_symb = ''\n",
    "\n",
    "    for index in inds:\n",
    "        current = index\n",
    "\n",
    "        if current == prev_symb:\n",
    "            continue\n",
    "\n",
    "        prev_symb = current\n",
    "        text += ind2char[current]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c8e886e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_decode2(inds) -> str:\n",
    "    \"\"\"\n",
    "    CTC decoding implementation.\n",
    "\n",
    "    Args:\n",
    "        inds (list): list of tokens.\n",
    "    Returns:\n",
    "        decoded_text (str): decoded text without empty tokens and\n",
    "            repetitions.\n",
    "    \"\"\"\n",
    "    decoded = []\n",
    "    prev_char = None\n",
    "    for ind in inds:\n",
    "        cur_char = ind2char[int(ind)]\n",
    "        if cur_char != '' and cur_char != prev_char:\n",
    "            decoded.append(ind2char[int(ind)])\n",
    "        prev_char = ind2char[int(ind)]\n",
    "    return \"\".join(decoded).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "595b3eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctc_decode1([1,2,2,2,3,3,4,5]) == ctc_decode2([1,2,2,2,3,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03843dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics.utils import calc_cer, calc_wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bdc592e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 206, 28])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2, 206, 28)\n",
    "torch.nn.functional.log_softmax(a, dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0617b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert calc_cer('hello', 'hallo') == 0.2\n",
    "assert calc_wer('hello world', 'hallo word') == 1\n",
    "assert calc_cer('', '') == 0\n",
    "assert calc_wer('', '') == 0\n",
    "assert calc_wer('', 'a') == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c2036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3])\n",
      "aiah\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics.wer import BeamSearchWERMetric\n",
    "beam_search_wer = BeamSearchWERMetric(text_encoder)\n",
    "log_probs = torch.randn(1, 3, len(text_encoder.vocab))\n",
    "log_probs_length = torch.tensor(log_probs.shape[1]).unsqueeze(0)\n",
    "print(log_probs_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40df95e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiah\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search_wer(log_probs, log_probs_length, ['aia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0a898ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.metrics.сer'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mсer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeamSearchСERMetric\n\u001b[32m      2\u001b[39m beam_search_сer = BeamSearchСERMetric(text_encoder)\n\u001b[32m      3\u001b[39m log_probs = torch.randn(\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[38;5;28mlen\u001b[39m(text_encoder.vocab))\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src.metrics.сer'"
     ]
    }
   ],
   "source": [
    "from src.metrics.сer import BeamSearchСERMetric\n",
    "beam_search_сer = BeamSearchСERMetric(text_encoder)\n",
    "log_probs = torch.randn(1, 3, len(text_encoder.vocab))\n",
    "log_probs_length = torch.tensor(log_probs.shape[1]).unsqueeze(0)\n",
    "print(log_probs_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6d9e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1, 3, 5).squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2acff24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1, 5)\n",
    "a[0:1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed7b3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2588d2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1, 5).squeeze(0)\n",
    "b = torch.randn(1, 3).squeeze(0)\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "pad_sequence([a, b], batch_first=True, padding_value=0).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d1f7cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3, 1).transpose(1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "452057fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.randn(1, 10)\n",
    "t2 = torch.randn(1, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f2f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequence([t1.squeezeи(0), t2.squeeze(0)], batch_first=True, padding_value=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ebe143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53349740",
   "metadata": {},
   "outputs": [],
   "source": [
    "T, V = 200, 28\n",
    "log_probs = torch.randn(T, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "448f7f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics.utils import ctc_beam_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96684950",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mctc_beam_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctc_blank\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "ctc_beam_search(log_probs, ctc_blank='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba5c5f05",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple expected at most 1 argument, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[32m3\u001b[39m), \u001b[32m4\u001b[39m), \u001b[32m5\u001b[39m))\n",
      "\u001b[31mTypeError\u001b[39m: tuple expected at most 1 argument, got 2"
     ]
    }
   ],
   "source": [
    "list(tuple(tuple(tuple(tuple(1, 2), 3), 4), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21dbea0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs[:100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd2d5776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), 3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tuple((tuple((1, 2)), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a983038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b925a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_items = [{'spectrogram': torch.randn(1, 3, 20), 'text_encoded': torch.randn(1, 7)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "05aea4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_levon(dataset_items: list[dict]):\n",
    "    \"\"\"\n",
    "    Collate and pad fields in the dataset items.\n",
    "    Converts individual items into a batch.\n",
    "\n",
    "    Args:\n",
    "        dataset_items (list[dict]): list of objects from\n",
    "            dataset.__getitem__.\n",
    "    Returns:\n",
    "        result_batch (dict[Tensor]): dict, containing batch-version\n",
    "            of the tensors.\n",
    "    \"\"\"\n",
    "    if not dataset_items:\n",
    "        return {}\n",
    "\n",
    "    batch = {}\n",
    "\n",
    "    for sample in dataset_items:\n",
    "        for key, val in sample.items():\n",
    "            if key not in batch:\n",
    "                batch[key] = []\n",
    "            batch[key].append(val)\n",
    "\n",
    "    def pad_tensors(tensors):\n",
    "        # список тензоров. Нашли макс длину\n",
    "        max_len = max(t.shape[-1] for t in tensors)\n",
    "        padded_tensors = []\n",
    "        lengths = []\n",
    "        for t in tensors:\n",
    "            # текущая длина\n",
    "            lengths.append(t.shape[-1])\n",
    "            # сколько допаддить\n",
    "            padding_size = max_len - t.shape[-1]\n",
    "            padded = nn.functional.pad(t, (0, padding_size))\n",
    "            padded_tensors.append(padded)\n",
    "        padded_tensors = torch.concat(padded_tensors)\n",
    "        lengths = torch.tensor(lengths)\n",
    "        return padded_tensors, lengths\n",
    "\n",
    "    keys = list(batch.keys())\n",
    "    for key in keys:\n",
    "        if key in ['audio', 'spectrogram', 'text_encoded']:\n",
    "            padded, lengths = pad_tensors(batch[key])\n",
    "            batch[key] = padded\n",
    "            batch[key + '_length'] = lengths\n",
    "        elif key in ['text', 'audio_path']:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected key `%s` encountered\" % (key,))\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3b1fac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "levon_collate = collate_fn_levon(dataset_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c111aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(dataset_items: list[dict]):\n",
    "    \"\"\"\n",
    "    Collate and pad fields in the dataset items.\n",
    "    Converts individual items into a batch.\n",
    "\n",
    "    Args:\n",
    "        dataset_items (list[dict]): list of objects from\n",
    "            dataset.__getitem__.\n",
    "    Returns:\n",
    "        result_batch (dict[Tensor]): dict, containing batch-version\n",
    "            of the tensors.\n",
    "    \"\"\"\n",
    "    result_batch = {\n",
    "        key: []\n",
    "        for key in [\n",
    "            \"audio\",\n",
    "            \"spectrogram\",\n",
    "            \"text\",\n",
    "            \"text_encoded\",\n",
    "            \"audio_path\",\n",
    "            \"spectrogram_length\",\n",
    "            \"text_encoded_length\",\n",
    "        ]\n",
    "    }\n",
    "    if not dataset_items:\n",
    "        return result_batch\n",
    "    \n",
    "    # print(dataset_items[0]['spectrogram'].shape, dataset_items[1]['spectrogram'].shape)\n",
    "    # assert 1 == 0\n",
    "\n",
    "    for element in dataset_items:\n",
    "        # result_batch[\"audio\"].append(element[\"audio\"])\n",
    "        # result_batch[\"audio_path\"].append(element[\"audio_path\"])\n",
    "\n",
    "        result_batch[\"spectrogram\"].append(\n",
    "            element[\"spectrogram\"].squeeze(0).transpose(0, 1) # (1, F, T) -> (T, F)\n",
    "        )\n",
    "        # result_batch[\"spectrogram_length\"].append(element[\"spectrogram\"].shape[-1])\n",
    "\n",
    "        # result_batch[\"text\"].append(element[\"text\"])\n",
    "        result_batch[\"text_encoded\"].append(element[\"text_encoded\"].transpose(-1, -2))\n",
    "        # result_batch[\"text_encoded_length\"].append(element[\"text_encoded\"].shape[-1])\n",
    "\n",
    "    result_batch[\"spectrogram\"] = (\n",
    "        pad_sequence(result_batch[\"spectrogram\"], batch_first=True)\n",
    "        .transpose(-1, -2)\n",
    "        .contiguous()\n",
    "    )\n",
    "    # result_batch[\"spectrogram_length\"] = torch.tensor(\n",
    "    #     result_batch[\"spectrogram_length\"], dtype=torch.int\n",
    "    # )\n",
    "\n",
    "    result_batch[\"text_encoded\"] = (\n",
    "        pad_sequence(result_batch[\"text_encoded\"], batch_first=True)\n",
    "        .squeeze(-1)\n",
    "        .contiguous()\n",
    "    )\n",
    "    # result_batch[\"text_encoded_length\"] = torch.tensor(\n",
    "    #     result_batch[\"text_encoded_length\"], dtype=torch.int\n",
    "    # )\n",
    "\n",
    "    return result_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ddf06e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_collate = collate_fn(dataset_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "df88a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "levon_spec = levon_collate['spectrogram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1298f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_spec = my_collate['spectrogram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "79df7c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levon_spec.shape == my_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "176d0d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2236, -0.7313, -0.2119, -0.6008, -1.3219],\n",
       "         [-2.0201,  0.7774, -0.8372,  0.7074,  0.8578],\n",
       "         [-1.2288,  2.3449, -0.0179, -2.6620,  0.5698]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levon_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2aa03dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2236, -0.7313, -0.2119, -0.6008, -1.3219],\n",
       "         [-2.0201,  0.7774, -0.8372,  0.7074,  0.8578],\n",
       "         [-1.2288,  2.3449, -0.0179, -2.6620,  0.5698]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2949fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1954, -1.7053, -1.2088,  1.7237,  0.7177, -0.2447,  1.2513]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levon_enc = levon_collate['text_encoded']\n",
    "levon_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cd904023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1954, -1.7053, -1.2088,  1.7237,  0.7177, -0.2447,  1.2513]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_enc = my_collate['text_encoded']\n",
    "my_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d6e4121d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(levon_enc, my_enc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
