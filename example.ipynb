{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93dc688f",
   "metadata": {},
   "source": [
    "#### –ù–µ —Å–º–æ–≥ –∏–∑–±–∞–≤–∏—Ç—å—Å—è –æ—Ç NaN –ª–æ—Å—Å–∞ –≤ torch_deepspeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f83dbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding save directory '/Users/ivanpodoynikov/DLA/ASR_DLA/saved/torch_deepspeech'...\n",
      "Logging git commit and patch...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mipodoynikov\u001b[0m (\u001b[33mipodoynikov-yandex\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m setting up run u9ehf7f1 (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run u9ehf7f1 (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run u9ehf7f1 (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run u9ehf7f1 (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/ivanpodoynikov/DLA/ASR_DLA/wandb/run-20251019_234856-u9ehf7f1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtorch_deepspeech\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ipodoynikov-yandex/pytorch_template_asr_example\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ipodoynikov-yandex/pytorch_template_asr_example/runs/u9ehf7f1\u001b[0m\n",
      "/Users/ivanpodoynikov/DLA/ASR_DLA/project_env/lib/python3.11/site-packages/torch_audiomentations/core/transforms_interface.py:76: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
      "  >>> augment = Gain(..., output_type='dict')\n",
      "  >>> augmented_samples = augment(samples).samples\n",
      "  warnings.warn(\n",
      "61 (2.3%) records are longer then 20.0 seconds. Excluding them.\n",
      "292 (10.8%) records are longer then 200 characters. Excluding them.\n",
      "Filtered 292 (10.8%) records  from dataset\n",
      "61 (2.3%) records are longer then 20.0 seconds. Excluding them.\n",
      "292 (10.8%) records are longer then 200 characters. Excluding them.\n",
      "Filtered 292 (10.8%) records  from dataset\n",
      "DeepSpeechWrapper(\n",
      "  (net): DeepSpeech(\n",
      "    (fc1): FullyConnected(\n",
      "      (fc): Linear(in_features=128, out_features=2048, bias=True)\n",
      "    )\n",
      "    (fc2): FullyConnected(\n",
      "      (fc): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    )\n",
      "    (fc3): FullyConnected(\n",
      "      (fc): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    )\n",
      "    (bi_rnn): RNN(2048, 2048, bidirectional=True)\n",
      "    (fc4): FullyConnected(\n",
      "      (fc): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    )\n",
      "    (out): Linear(in_features=2048, out_features=28, bias=True)\n",
      "  )\n",
      ")\n",
      "All parameters: 29696028\n",
      "Trainable parameters: 29696028\n",
      "train:   0%|                                             | 0/50 [00:00<?, ?it/s]Output: tensor([[[-3.3474, -3.3422, -3.3605,  ..., -3.3369, -3.3339, -3.3147],\n",
      "         [-3.3481, -3.3415, -3.3596,  ..., -3.3382, -3.3349, -3.3138],\n",
      "         [-3.3480, -3.3416, -3.3588,  ..., -3.3385, -3.3345, -3.3138],\n",
      "         ...,\n",
      "         [-3.3484, -3.3415, -3.3590,  ..., -3.3384, -3.3346, -3.3134],\n",
      "         [-3.3488, -3.3415, -3.3599,  ..., -3.3379, -3.3352, -3.3139],\n",
      "         [-3.3479, -3.3428, -3.3589,  ..., -3.3388, -3.3341, -3.3152]],\n",
      "\n",
      "        [[-3.3472, -3.3422, -3.3604,  ..., -3.3369, -3.3338, -3.3147],\n",
      "         [-3.3481, -3.3414, -3.3595,  ..., -3.3381, -3.3349, -3.3138],\n",
      "         [-3.3479, -3.3415, -3.3588,  ..., -3.3386, -3.3345, -3.3138],\n",
      "         ...,\n",
      "         [-3.3484, -3.3415, -3.3590,  ..., -3.3384, -3.3346, -3.3134],\n",
      "         [-3.3488, -3.3415, -3.3599,  ..., -3.3379, -3.3352, -3.3139],\n",
      "         [-3.3479, -3.3428, -3.3589,  ..., -3.3388, -3.3341, -3.3152]]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Train Epoch: 1 [0/50 (0%)] Loss: 12.319366\n",
      "train:   2%|‚ñã                                    | 1/50 [00:10<08:19, 10.19s/it]Output: tensor([[[-3.0662, -3.3197, -3.4219,  ..., -3.3717, -3.3551, -3.2291],\n",
      "         [-3.0310, -3.3194, -3.4311,  ..., -3.3768, -3.3608, -3.2178],\n",
      "         [-3.0184, -3.3200, -3.4335,  ..., -3.3784, -3.3628, -3.2141],\n",
      "         ...,\n",
      "         [-3.0212, -3.3211, -3.4321,  ..., -3.3777, -3.3626, -3.2155],\n",
      "         [-3.0354, -3.3224, -3.4279,  ..., -3.3746, -3.3617, -3.2200],\n",
      "         [-3.0731, -3.3267, -3.4159,  ..., -3.3713, -3.3592, -3.2329]],\n",
      "\n",
      "        [[-3.0661, -3.3196, -3.4220,  ..., -3.3718, -3.3552, -3.2291],\n",
      "         [-3.0308, -3.3194, -3.4311,  ..., -3.3769, -3.3609, -3.2177],\n",
      "         [-3.0181, -3.3199, -3.4335,  ..., -3.3784, -3.3629, -3.2140],\n",
      "         ...,\n",
      "         [-3.0212, -3.3211, -3.4321,  ..., -3.3777, -3.3626, -3.2155],\n",
      "         [-3.0354, -3.3224, -3.4279,  ..., -3.3746, -3.3617, -3.2200],\n",
      "         [-3.0731, -3.3267, -3.4159,  ..., -3.3713, -3.3592, -3.2329]]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "train:   4%|‚ñà‚ñç                                   | 2/50 [00:19<07:53,  9.86s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:   6%|‚ñà‚ñà‚ñè                                  | 3/50 [00:28<07:09,  9.15s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:   8%|‚ñà‚ñà‚ñâ                                  | 4/50 [00:36<06:53,  8.98s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  10%|‚ñà‚ñà‚ñà‚ñã                                 | 5/50 [00:45<06:38,  8.86s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  12%|‚ñà‚ñà‚ñà‚ñà‚ñç                                | 6/50 [00:53<06:17,  8.59s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                               | 7/50 [01:01<06:02,  8.43s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 8/50 [01:09<05:50,  8.34s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 9/50 [01:18<05:40,  8.30s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 10/50 [01:26<05:36,  8.40s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 11/50 [01:34<05:26,  8.36s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 12/50 [01:43<05:16,  8.32s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 13/50 [01:51<05:03,  8.20s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 14/50 [01:58<04:52,  8.12s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 15/50 [02:06<04:41,  8.04s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 16/50 [02:14<04:29,  7.93s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 17/50 [02:22<04:24,  8.03s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 18/50 [02:31<04:20,  8.14s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 19/50 [02:40<04:19,  8.37s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                     | 20/50 [02:48<04:13,  8.45s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 21/50 [02:56<03:58,  8.23s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 22/50 [03:04<03:49,  8.21s/it]Output: tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 23/50 [03:12<03:42,  8.25s/it]^C\n",
      "object address  : 0x12b08a1a0\n",
      "object refcount : 2\n",
      "object type     : 0x1039efc30\n",
      "object type name: KeyboardInterrupt\n",
      "object repr     : KeyboardInterrupt()\n",
      "lost sys.stderr\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 246, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 297, in _fixup_main_from_path\n",
      "Saving model on keyboard interrupt\n",
      "    main_content = runpy.run_path(main_path,\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen runpy>\", line 291, in run_path\n",
      "  File \"<frozen runpy>\", line 98, in _run_module_code\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/ivanpodoynikov/DLA/ASR_DLA/train.py\", line 8, in <module>\n",
      "    from src.datasets.data_utils import get_dataloaders\n",
      "  File \"/Users/ivanpodoynikov/DLA/ASR_DLA/src/datasets/__init__.py\", line 1, in <module>\n",
      "    from src.datasets.common_voice import CommonVoiceDataset\n",
      "  File \"/Users/ivanpodoynikov/DLA/ASR_DLA/src/datasets/common_voice.py\", line 8, in <module>\n",
      "    from datasets import load_dataset\n",
      "  File \"/Users/ivanpodoynikov/DLA/ASR_DLA/project_env/lib/python3.11/site-packages/datasets/__init__.py\", line 17, in <module>\n",
      "    from .arrow_dataset import Column, Dataset\n",
      "  File \"/Users/ivanpodoynikov/DLA/ASR_DLA/project_env/lib/python3.11/site-packages/datasets/arrow_dataset.py\", line 59, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/Users/ivanpodoynikov/DLA/ASR_DLA/project_env/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/Users/ivanpodoynikov/DLA/ASR_DLA/project_env/lib/python3.11/site-packages/pandas/core/api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"/Users/ivanpodoynikov/DLA/ASR_DLA/project_env/lib/python3.11/site-packages/pandas/_libs/__init__.py\", line 18, in <module>\n",
      "    from pandas._libs.interval import Interval\n",
      "  File \"pandas/_libs/interval.pyx\", line 1, in init pandas._libs.interval\n",
      "  File \"pandas/_libs/hashtable.pyx\", line 1, in init pandas._libs.hashtable\n",
      "  File \"pandas/_libs/missing.pyx\", line 40, in init pandas._libs.missing\n",
      "  File \"<frozen importlib._bootstrap>\", line 405, in parent\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py -cn=torch_deepspeech.yaml datasets=onebatchtest trainer.n_epochs=1 trainer.epoch_len=50 dataloader.batch_size=2 trainer.seed=2 trainer.override=True writer.run_name=\"torch_deepspeech\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6615ab",
   "metadata": {},
   "source": [
    "#### –†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ deepspeech2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd30f547",
   "metadata": {},
   "source": [
    "–ù–∞ –≤–∞–Ω–±–∞—Ç—á–µ (–∑–∞–ø—É—Å–∫ –Ω–∞ –∫–∞–≥–ª): https://wandb.ai/ipodoynikov-yandex/pytorch_template_asr_example/runs/flru76i2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67558f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train.py -cn=deepspeech2.yaml datasets=onebatchtest trainer.n_epochs=5 trainer.epoch_len=50 dataloader.batch_size=2 trainer.seed=2 trainer.override=True writer.run_name=\"deepspeech2_onebatch_review\"          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d65a9e",
   "metadata": {},
   "source": [
    "–ù–∞ example: https://wandb.ai/ipodoynikov-yandex/pytorch_template_asr_example/runs/f9ranspu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train.py -cn=deepspeech2.yaml datasets=example trainer.n_epochs=10 trainer.epoch_len=1000 dataloader.batch_size=32 trainer.seed=2 trainer.override=True writer.run_name=\"deepspeech2_example\"          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d2752",
   "metadata": {},
   "source": [
    "–†–µ–∑—É–ª—å—Ç–∞—Ç - –Ω–µ–∞–¥–µ–∫–≤–∞—Ç–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫. –ù–µ—Ç –ø–∞–¥–µ–Ω–∏—è –ª–æ—Å—Å–∞. –í prediction –≤—ã–¥–∞–µ—Ç –æ–¥–Ω—É –±—É–∫–≤—É"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f5e1b",
   "metadata": {},
   "source": [
    "### –†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ conformer - –≤ —Ü–µ–ª–æ–º –ø–ª–æ—Ö–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40cb277",
   "metadata": {},
   "source": [
    "–ù–∞ –≤–∞–Ω–±–∞—Ç—á–µ: https://wandb.ai/ipodoynikov-yandex/pytorch_template_asr_example/runs/i2mizlyo?nw=nwuseripodoynikov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf504253",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train.py -cn=conformer.yaml datasets=onebatchtest trainer.n_epochs=20 trainer.epoch_len=200 dataloader.batch_size=2 trainer.seed=2 trainer.override=True writer.run_name=\"conformer_onebatchtest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbab191",
   "metadata": {},
   "source": [
    "–ù–∞ example: https://wandb.ai/ipodoynikov-yandex/pytorch_template_asr_example/runs/wb6yx2w3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4391530",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train.py -cn=conformer.yaml metrics=deepspeech2 dataloader.batch_size=8 trainer.seed=3 trainer.override=True trainer.epoch_len=200 trainer.n_epochs=2000 datasets=example writer.run_name=\"conformer_example\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acd9f92",
   "metadata": {},
   "source": [
    "–í–Ω–æ–≤—å –Ω–µ–∞–¥–µ–∫–≤–∞—Ç–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫. –í –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö –ø–æ—á–µ–º—É-—Ç–æ –ø—É—Å—Ç–æ–π –ø—Ä–µ–¥–∏–∫—à–Ω"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
